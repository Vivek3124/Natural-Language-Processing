{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95bc021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class                                                SMS\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "ham_spam_sms = pd.read_csv(\"SMSSpamCollection.txt\",\n",
    "                            delimiter = \"\\t\",header=None, names=['Class', 'SMS'])\n",
    "ham_spam_sms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6be5f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we are counting how many are spam and how many are hams in the dataset\n",
    "\n",
    "ham_spam_sms['Class'].value_counts(normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1166299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are randomizing the dataset so that our model can learn properly from distributed datasets.\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "training_test = round(len(ham_spam_sms) * 0.80)\n",
    "\n",
    "train_set_final = ham_spam_sms[:training_test].reset_index(drop = True)\n",
    "test_set_final = ham_spam_sms[training_test:].reset_index(drop = True)\n",
    "\n",
    "# prepare cross validation\n",
    "kfold = KFold(5)\n",
    "train_set = []\n",
    "test_set = []\n",
    "\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(train_set_final):\n",
    "    train_set.append(train)\n",
    "    test_set.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd17867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set_final[train_set_final.index.isin(train_set[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d121d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = (\"A\",\"B\")\n",
    "# per_sms_words_count = {unique_word : [0] * len(train_set_one['SMS']) for unique_word in vocab}\n",
    "# word_count = pd.DataFrame(per_sms_words_count)\n",
    "# cleaned_train_set = pd.concat([train_set_one, word_count], axis = 1)\n",
    "# cleaned_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72676122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-7f45884da382>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set_i['SMS'] = train_set_i['SMS'].str.replace('\\W', ' ', regex = True) # It Removes punctuation\n",
      "<ipython-input-6-7f45884da382>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set_i['SMS'] = train_set_i['SMS'].str.lower()\n",
      "<ipython-input-6-7f45884da382>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set_i['SMS'] = train_set_i['SMS'].str.split() #splitting the string at the space character in train_set\n",
      "<ipython-input-6-7f45884da382>:139: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_set_i['predicted'] = validation_set_i['SMS'].apply(classify_test_set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold result is\n",
      "Correct: 750\n",
      "Incorrect: 142\n",
      "Accuracy: 84.08071748878923\n",
      "##################\n",
      "2 fold result is\n",
      "Correct: 822\n",
      "Incorrect: 70\n",
      "Accuracy: 92.152466367713\n",
      "##################\n",
      "3 fold result is\n",
      "Correct: 873\n",
      "Incorrect: 19\n",
      "Accuracy: 97.86995515695067\n",
      "##################\n",
      "4 fold result is\n",
      "Correct: 876\n",
      "Incorrect: 15\n",
      "Accuracy: 98.31649831649831\n",
      "##################\n",
      "5 fold result is\n",
      "Correct: 879\n",
      "Incorrect: 12\n",
      "Accuracy: 98.65319865319864\n",
      "##################\n"
     ]
    }
   ],
   "source": [
    "# Training the model for k folds with training datset (80% of orginal data)\n",
    "\n",
    "# declaring empty dictionaries and variables to store parameters for every fold\n",
    "para_spam_k = {}\n",
    "para_ham_k = {}\n",
    "prob_spam_k = 0\n",
    "prob_ham_k = 0\n",
    "\n",
    "k = 5\n",
    "    \n",
    "for i in range(0, k):\n",
    "    \n",
    "    train_set_i = train_set_final[train_set_final.index.isin(train_set[i])]\n",
    "    validation_set_i = train_set_final[train_set_final.index.isin(test_set[i])]\n",
    "    \n",
    "    \n",
    "    train_set_i['SMS'] = train_set_i['SMS'].str.replace('\\W', ' ', regex = True) # It Removes punctuation\n",
    "    \n",
    "    #It is used to lowercase all strings\n",
    "    train_set_i['SMS'] = train_set_i['SMS'].str.lower()\n",
    "\n",
    "################################################\n",
    "\n",
    "    train_set_i['SMS'] = train_set_i['SMS'].str.split() #splitting the string at the space character in train_set\n",
    "\n",
    "    vocabs = [] #declaring a list to contain all words\n",
    "\n",
    "    for message in train_set_i['SMS']: #appending all the training words in list\n",
    "        for word in message:\n",
    "            vocabs.append(word)\n",
    "\n",
    "    vocabs = list(set(vocabs)) #this is done to eliminate the duplicates by using set function\n",
    "    \n",
    "\n",
    "####################################################\n",
    "#initialising a dictionary with all value 0 and length of each dictionary is words in vocabs\n",
    "\n",
    "    per_sms_words_count = {unique_word : [0] * len(train_set_i['SMS']) for unique_word in vocabs}\n",
    "\n",
    "    for index, sms in enumerate(train_set_i['SMS']):\n",
    "        for word in sms:\n",
    "            per_sms_words_count[word][index] += 1\n",
    "        \n",
    "#####################################################\n",
    "        \n",
    "    #it will display how many times word is used in a sentence for an index\n",
    "\n",
    "    word_count = pd.DataFrame(per_sms_words_count)\n",
    "    \n",
    "    cleaned_train_set = pd.concat([train_set_i, word_count], axis = 1)\n",
    "\n",
    "#done with cleaning the dataset\n",
    "\n",
    "\n",
    "########################################################\n",
    "\n",
    "     #isolating sam and ham messages first\n",
    "\n",
    "    spam_messages  = cleaned_train_set[cleaned_train_set['Class'] == 'spam']\n",
    "    ham_messages = cleaned_train_set[cleaned_train_set['Class'] == 'ham']\n",
    "\n",
    "     #probability of spam and ham messages\n",
    "    prob_ham = len(ham_messages)/len(cleaned_train_set)\n",
    "    prob_spam = len(spam_messages)/len(cleaned_train_set)\n",
    "    \n",
    "    prob_ham_k += (prob_ham)\n",
    "    prob_spam_k += (prob_spam)\n",
    "\n",
    "    #no. of words in all spam msgs\n",
    "    words_spam_messages = spam_messages['SMS'].apply(len)\n",
    "    n_spam = words_spam_messages.sum()\n",
    "\n",
    "    #no. of words in all ham msgs\n",
    "    words_ham_messages = ham_messages['SMS'].apply(len)\n",
    "    n_ham = words_ham_messages.sum()\n",
    "\n",
    "    #no. of vacabulary\n",
    "    n_vocabs = len(vocabs)\n",
    "\n",
    "    #laplace smoothening\n",
    "    alpha = 1\n",
    "\n",
    "#laplace smoothening is used so that prob can't be zero otherwise our classifier will classify that\n",
    "#message as only a single classifier no matter how many times spam words has been occured in that message\n",
    "        \n",
    "    \n",
    "###############################################################\n",
    "\n",
    "    #initiating parameters    (conditional probabilities)\n",
    "    parameters_spam = {unique_word:0 for unique_word in vocabs}\n",
    "    parameters_ham = {unique_word:0 for unique_word in vocabs}\n",
    "\n",
    "\n",
    "#calculating the parameters   (conditional probabilities)\n",
    "    for words in vocabs:\n",
    "        n_words_given_spam = spam_messages[words].sum()\n",
    "        prob_words_given_spam = (n_words_given_spam + alpha)/(n_spam + alpha*n_vocabs)\n",
    "        \n",
    "        parameters_spam[words] = prob_words_given_spam\n",
    "        if words in para_spam_k.keys():\n",
    "            para_spam_k[words] += prob_words_given_spam\n",
    "        else:    \n",
    "            para_spam_k[words] = prob_words_given_spam\n",
    "    \n",
    "        n_words_given_ham = ham_messages[words].sum()\n",
    "        prob_words_given_ham = (n_words_given_ham + alpha)/(n_ham + alpha*n_vocabs)\n",
    "        \n",
    "        parameters_ham[words] = prob_words_given_ham\n",
    "        if words in para_ham_k.keys():\n",
    "            para_ham_k[words] += prob_words_given_ham\n",
    "        else:    \n",
    "            para_ham_k[words] = prob_words_given_ham\n",
    "        \n",
    "        \n",
    "\n",
    "##################################################################\n",
    "\n",
    "#writing the function to classify the message\n",
    "\n",
    "    def classify_test_set(msg):\n",
    "        msg = re.sub('\\W', ' ', msg)\n",
    "        msg = msg.lower().split()\n",
    "    \n",
    "        prob_spam_giv_msg = prob_spam #initial guess for spam based on the training dataset : prior probability\n",
    "        prob_ham_giv_msg = prob_ham #initial guess for ham based on the training dataset : prior\n",
    "    \n",
    "        for word in msg:\n",
    "            if word in parameters_spam:\n",
    "                prob_spam_giv_msg *= parameters_spam[word]\n",
    "        \n",
    "            if word in parameters_ham:\n",
    "                prob_ham_giv_msg *= parameters_ham[word]\n",
    "    \n",
    "        if prob_spam_giv_msg > prob_ham_giv_msg:\n",
    "            return 'spam'\n",
    "        else:\n",
    "            return 'ham'\n",
    "\n",
    "    validation_set_i['predicted'] = validation_set_i['SMS'].apply(classify_test_set)\n",
    "    \n",
    "    correct = 0\n",
    "    total = validation_set_i.shape[0]\n",
    "\n",
    "    for row in validation_set_i.iterrows():\n",
    "        row = row[1]\n",
    "        if row['Class'] == row['predicted']:\n",
    "            correct += 1\n",
    "\n",
    "    print(i+1, end = '')\n",
    "    print(\" fold result is\")\n",
    "    print('Correct:', correct)\n",
    "    print('Incorrect:', total - correct)\n",
    "    print('Accuracy:', correct/total*100)\n",
    "    print(\"##################\")\n",
    "\n",
    "#acuracy can be adjusted by providing more training set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f30a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # no_ham = train_set_final['Class'].value_counts()[0]\n",
    "# # no_spam = train_set_final['Class'].value_counts()[1]\n",
    "# # total_msg = no_ham + no_spam\n",
    "# # prob_h = no_ham/total_msg\n",
    "# # prob_s = no_spam/total_msg\n",
    "# print(prob_h,prob_s)\n",
    "# print(prob_ham_k /5,prob_spam_k /5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28a4c5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final result is\n",
      "Correct: 1078\n",
      "Incorrect: 36\n",
      "Accuracy: 96.76840215439856\n",
      "##################\n"
     ]
    }
   ],
   "source": [
    "for para in para_spam_k:\n",
    "    para_spam_k[para] /= 5\n",
    "\n",
    "for para in para_ham_k:\n",
    "    para_ham_k[para] /= 5\n",
    "\n",
    "def classify_test_set_final(msg):\n",
    "    msg = re.sub('\\W', ' ', msg)\n",
    "    msg = msg.lower().split()\n",
    "    \n",
    "    prob_spam_giv_msg = prob_spam_k /5 #initial guess for spam based on the training dataset\n",
    "    prob_ham_giv_msg = prob_ham_k /5 #initial guess for ham based on the training dataset\n",
    "\n",
    "    for word in msg:\n",
    "        if word in para_spam_k:\n",
    "            prob_spam_giv_msg *= para_spam_k[word]\n",
    "\n",
    "        if word in parameters_ham:\n",
    "            prob_ham_giv_msg *= para_ham_k[word]\n",
    "    \n",
    "    if prob_spam_giv_msg > prob_ham_giv_msg:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ham'\n",
    "\n",
    "        \n",
    "test_set_final['predicted'] = test_set_final['SMS'].apply(classify_test_set_final)\n",
    "    \n",
    "correct = 0\n",
    "total = test_set_final.shape[0]\n",
    "\n",
    "for row in test_set_final.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Class'] == row['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "print(\"Final result is\")\n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total*100)\n",
    "print(\"##################\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d7fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
