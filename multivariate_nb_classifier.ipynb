{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f3a595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class                                                SMS\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "\n",
    "\n",
    "ham_spam_sms = pd.read_csv(\"SMSSpamCollection.txt\",\n",
    "                            delimiter = \"\\t\",header=None, names=['Class', 'SMS'])\n",
    "ham_spam_sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b7190e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_spam_sms['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed1a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are randomizing the dataset so that our model can learn properly from distributed datasets.\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "training_test = round(len(ham_spam_sms) * 0.80)\n",
    "\n",
    "train_set_final = ham_spam_sms[:training_test].reset_index(drop = True)\n",
    "test_set_final = ham_spam_sms[training_test:].reset_index(drop = True)\n",
    "\n",
    "# prepare cross validation\n",
    "kfold = KFold(5)\n",
    "train_set = []\n",
    "test_set = []\n",
    "\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(train_set_final):\n",
    "    train_set.append(train)\n",
    "    test_set.append(test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae03d5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     3856\n",
      "spam     602\n",
      "Name: Class, dtype: int64\n",
      "ham     969\n",
      "spam    145\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set_final['Class'].value_counts())\n",
    "print(test_set_final['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01bbf2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-65b1362600f8>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set_i['SMS'] = train_set_i['SMS'].str.replace('\\W', ' ', regex = True) # It Removes punctuation\n",
      "<ipython-input-6-65b1362600f8>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set_i['SMS'] = train_set_i['SMS'].str.lower()\n",
      "<ipython-input-6-65b1362600f8>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_set_i['SMS'] = train_set_i['SMS'].str.split() #splitting the string at the space character in train_set\n",
      "<ipython-input-6-65b1362600f8>:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_set_i['predicted'] = validation_set_i['SMS'].apply(classify_test_set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold result is\n",
      "Correct: 751\n",
      "Incorrect: 141\n",
      "Accuracy: 84.19282511210763\n",
      "##################\n",
      "2 fold result is\n",
      "Correct: 855\n",
      "Incorrect: 37\n",
      "Accuracy: 95.85201793721974\n",
      "##################\n",
      "3 fold result is\n",
      "Correct: 871\n",
      "Incorrect: 21\n",
      "Accuracy: 97.6457399103139\n",
      "##################\n",
      "4 fold result is\n",
      "Correct: 872\n",
      "Incorrect: 19\n",
      "Accuracy: 97.8675645342312\n",
      "##################\n",
      "5 fold result is\n",
      "Correct: 867\n",
      "Incorrect: 24\n",
      "Accuracy: 97.3063973063973\n",
      "##################\n"
     ]
    }
   ],
   "source": [
    "# Training the model for k folds with training datset (80% of orginal data)\n",
    "\n",
    "# declaring empty dictionaries and variables to store parameters for every fold\n",
    "para_spam_k = {}\n",
    "para_ham_k = {}\n",
    "prob_spam_k = 0\n",
    "prob_ham_k = 0\n",
    "\n",
    "k = 5\n",
    "\n",
    "for i in range(0, k):\n",
    "    train_set_i = train_set_final[train_set_final.index.isin(train_set[i])]\n",
    "    validation_set_i = train_set_final[train_set_final.index.isin(test_set[i])]\n",
    "    accuracy = []\n",
    "    \n",
    "    train_set_i['SMS'] = train_set_i['SMS'].str.replace('\\W', ' ', regex = True) # It Removes punctuation\n",
    "    \n",
    "    #It is used to lowercase all strings\n",
    "    train_set_i['SMS'] = train_set_i['SMS'].str.lower()\n",
    "\n",
    "    train_set_i['SMS'] = train_set_i['SMS'].str.split() #splitting the string at the space character in train_set\n",
    "\n",
    "    vocabs = [] #declaring a list to contain all words\n",
    "\n",
    "    for message in train_set_i['SMS']: #appending all the training words in list\n",
    "        for word in message:\n",
    "            vocabs.append(word)\n",
    "\n",
    "    vocabs = list(set(vocabs)) #this is done to eliminate the duplicates by using set function\n",
    "    \n",
    "\n",
    "########################################################\n",
    "    #initialising a dictionary with all value 0 and length of each dictionary is words in vocabs\n",
    "\n",
    "    per_sms_words_presence = {unique_word : [0] * len(train_set_i['SMS']) for unique_word in vocabs}\n",
    "\n",
    "    for index, sms in enumerate(train_set_i['SMS']):\n",
    "        for word in sms:\n",
    "            if per_sms_words_presence[word][index] == 1:\n",
    "                continue\n",
    "            else:\n",
    "                per_sms_words_presence[word][index] = 1\n",
    "\n",
    "########################################################\n",
    "\n",
    "     #it will display how many times word is used in a sentence for an index\n",
    "\n",
    "    word_present = pd.DataFrame(per_sms_words_presence)\n",
    "    \n",
    "    cleaned_train_set = pd.concat([train_set_i, word_present], axis = 1)\n",
    "\n",
    "    #done with cleaning the dataset\n",
    "########################################################\n",
    "\n",
    "\n",
    "     #isolating sam and ham messages first\n",
    "\n",
    "    spam_messages  = cleaned_train_set[cleaned_train_set['Class'] == 'spam'] #no. of spam messages\n",
    "    ham_messages = cleaned_train_set[cleaned_train_set['Class'] == 'ham']  #no. of ham messages\n",
    "\n",
    "    #probability of spam and ham messages\n",
    "    prob_ham = len(ham_messages)/len(cleaned_train_set)\n",
    "    prob_spam = len(spam_messages)/len(cleaned_train_set)\n",
    "    \n",
    "    prob_ham_k += (prob_ham)\n",
    "    prob_spam_k += (prob_spam)\n",
    "\n",
    "\n",
    "    #no. of vacabulary\n",
    "    #n_vocabs = len(vocabs)\n",
    "\n",
    "    #laplace smoothening\n",
    "    alpha = 1\n",
    "\n",
    "    #laplace smoothening is used so that prob can't be zero otherwise our classifier will classify that\n",
    "    #message as only a single classifier no matter how many times spam words has been occured in that message\n",
    "\n",
    "\n",
    "    #initiating parameters(conditional probabilities)\n",
    "    parameters_spam = {unique_word:0 for unique_word in vocabs}\n",
    "    parameters_ham = {unique_word:0 for unique_word in vocabs}\n",
    "\n",
    "\n",
    "    #calculating the parameters(conditional probabilities)\n",
    "    for words in vocabs:\n",
    "        n_doc_given_spam = spam_messages[words].sum()\n",
    "        prob_words_given_spam = (n_doc_given_spam + alpha)/(len(spam_messages) + alpha*2)\n",
    "        parameters_spam[words] = prob_words_given_spam\n",
    "        if words in para_spam_k.keys():\n",
    "            para_spam_k[words] += prob_words_given_spam\n",
    "        else:    \n",
    "            para_spam_k[words] = prob_words_given_spam\n",
    "    \n",
    "        n_doc_given_ham = ham_messages[words].sum()\n",
    "        prob_words_given_ham = (n_doc_given_ham + alpha)/(len(ham_messages) + alpha*2)\n",
    "        parameters_ham[words] = prob_words_given_ham\n",
    "        if words in para_ham_k.keys():\n",
    "            para_ham_k[words] += prob_words_given_ham\n",
    "        else:    \n",
    "            para_ham_k[words] = prob_words_given_ham\n",
    "\n",
    "\n",
    "    def classify_test_set(msg):\n",
    "        \n",
    "        msg = re.sub('\\W', ' ', msg)\n",
    "        msg = msg.lower().split()\n",
    "    \n",
    "        prob_spam_giv_msg = (math.log(prob_spam)) #initial guess for spam based on the training dataset :prior probability\n",
    "        prob_ham_giv_msg = (math.log(prob_ham)) #initial guess for ham based on the training dataset\n",
    "    \n",
    "        for word in vocabs:\n",
    "            if word in msg:\n",
    "                prob_spam_giv_msg += (math.log(parameters_spam[word]))\n",
    "                prob_ham_giv_msg += (math.log(parameters_ham[word]))\n",
    "            else:\n",
    "                prob_spam_giv_msg += (math.log(1 - parameters_spam[word]))\n",
    "                prob_ham_giv_msg += (math.log(1 - parameters_ham[word]))\n",
    "                \n",
    "    \n",
    "        if prob_spam_giv_msg > prob_ham_giv_msg:\n",
    "            return 'spam'     \n",
    "        else:\n",
    "            return 'ham'\n",
    "        \n",
    "        \n",
    "    validation_set_i['predicted'] = validation_set_i['SMS'].apply(classify_test_set)\n",
    "\n",
    "    correct = 0\n",
    "    total = validation_set_i.shape[0]\n",
    "\n",
    "    for row in validation_set_i.iterrows():\n",
    "        row = row[1]\n",
    "        if row['Class'] == row['predicted']:\n",
    "            correct += 1\n",
    "\n",
    "    print(i+1, end = '')\n",
    "    print(\" fold result is\")\n",
    "    print('Correct:', correct)\n",
    "    print('Incorrect:', total - correct)\n",
    "    acc = correct/total*100\n",
    "    print('Accuracy:', acc)\n",
    "    print(\"##################\")\n",
    "\n",
    "#acuracy can be adjusted by providing more training set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc45c9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8649618663077613 0.13503813369223866\n",
      "0.7265971419634372 0.11337594013615915\n"
     ]
    }
   ],
   "source": [
    "# no_ham = train_set_final['Class'].value_counts()[0]\n",
    "# no_spam = train_set_final['Class'].value_counts()[1]\n",
    "# total_msg = no_ham + no_spam\n",
    "# prob_h = no_ham/total_msg\n",
    "# prob_s = no_spam/total_msg\n",
    "# print(prob_h,prob_s)\n",
    "# print(prob_ham_k /5,prob_spam_k /5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b3f5833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final result is\n",
      "Correct: 1034\n",
      "Incorrect: 80\n",
      "Accuracy: 92.81867145421903\n",
      "##################\n"
     ]
    }
   ],
   "source": [
    "for para in para_spam_k:\n",
    "    para_spam_k[para] /= 5\n",
    "\n",
    "for para in para_ham_k:\n",
    "    para_ham_k[para] /= 5\n",
    "\n",
    "def classify_test_set_final(msg):\n",
    "    msg = re.sub('\\W', ' ', msg)\n",
    "    msg = msg.lower().split()\n",
    "    \n",
    "    prob_spam_giv_msg = math.log(prob_spam_k /5) #initial guess for spam based on the training dataset\n",
    "    prob_ham_giv_msg = math.log(prob_ham_k /5) #initial guess for ham based on the training dataset\n",
    "    \n",
    "    for word in vocabs:\n",
    "        if word in msg:\n",
    "            prob_spam_giv_msg += (math.log(para_spam_k[word]))\n",
    "            prob_ham_giv_msg += (math.log(para_ham_k[word]))\n",
    "        else:\n",
    "            prob_spam_giv_msg += (math.log(1 - para_spam_k[word]))\n",
    "            prob_ham_giv_msg += (math.log(1 - para_ham_k[word]))\n",
    "    \n",
    "    \n",
    "    if prob_spam_giv_msg > prob_ham_giv_msg:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ham'\n",
    "\n",
    "        \n",
    "test_set_final['predicted'] = test_set_final['SMS'].apply(classify_test_set_final)\n",
    "    \n",
    "correct = 0\n",
    "total = test_set_final.shape[0]\n",
    "\n",
    "for row in test_set_final.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Class'] == row['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "print(\"Final result is\")\n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total*100)\n",
    "print(\"##################\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5dab44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
